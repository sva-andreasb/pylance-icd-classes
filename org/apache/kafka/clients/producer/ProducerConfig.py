BOOTSTRAP_SERVERS_CONFIG = "String  \"bootstrap.servers\""
METADATA_MAX_AGE_CONFIG = "String  \"metadata.max.age.ms\""
BATCH_SIZE_CONFIG = "String  \"batch.size\""
ACKS_CONFIG = "String  \"acks\""
LINGER_MS_CONFIG = "String  \"linger.ms\""
CLIENT_ID_CONFIG = "String  \"client.id\""
SEND_BUFFER_CONFIG = "String  \"send.buffer.bytes\""
RECEIVE_BUFFER_CONFIG = "String  \"receive.buffer.bytes\""
MAX_REQUEST_SIZE_CONFIG = "String  \"max.request.size\""
RECONNECT_BACKOFF_MS_CONFIG = "String  \"reconnect.backoff.ms\""
RECONNECT_BACKOFF_MAX_MS_CONFIG = "String  \"reconnect.backoff.max.ms\""
MAX_BLOCK_MS_CONFIG = "String  \"max.block.ms\""
BUFFER_MEMORY_CONFIG = "String  \"buffer.memory\""
RETRY_BACKOFF_MS_CONFIG = "String  \"retry.backoff.ms\""
COMPRESSION_TYPE_CONFIG = "String  \"compression.type\""
METRICS_SAMPLE_WINDOW_MS_CONFIG = "String  \"metrics.sample.window.ms\""
METRICS_NUM_SAMPLES_CONFIG = "String  \"metrics.num.samples\""
METRICS_RECORDING_LEVEL_CONFIG = "String  \"metrics.recording.level\""
METRIC_REPORTER_CLASSES_CONFIG = "String  \"metric.reporters\""
MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = "String  \"max.in.flight.requests.per.connection\""
RETRIES_CONFIG = "String  \"retries\""
KEY_SERIALIZER_CLASS_CONFIG = "String  \"key.serializer\""
KEY_SERIALIZER_CLASS_DOC = "String  \"Serializer class for key that implements the <code>org.apache.kafka.common.serialization.Serializer</code> interface.\""
VALUE_SERIALIZER_CLASS_CONFIG = "String  \"value.serializer\""
VALUE_SERIALIZER_CLASS_DOC = "String  \"Serializer class for value that implements the <code>org.apache.kafka.common.serialization.Serializer</code> interface.\""
CONNECTIONS_MAX_IDLE_MS_CONFIG = "String  \"connections.max.idle.ms\""
PARTITIONER_CLASS_CONFIG = "String  \"partitioner.class\""
REQUEST_TIMEOUT_MS_CONFIG = "String  \"request.timeout.ms\""
INTERCEPTOR_CLASSES_CONFIG = "String  \"interceptor.classes\""
INTERCEPTOR_CLASSES_DOC = "String  \"A list of classes to use as interceptors. Implementing the <code>org.apache.kafka.clients.producer.ProducerInterceptor</code> interface allows you to intercept (and possibly mutate) the records received by the producer before they are published to the Kafka cluster. By default, there are no interceptors.\""
ENABLE_IDEMPOTENCE_CONFIG = "String  \"enable.idempotence\""
ENABLE_IDEMPOTENCE_DOC = "String  \"When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream. If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream. Note that enabling idempotence requires <code>max.in.flight.requests.per.connection</code> to be less than or equal to 5, <code>retries</code> to be greater than 0 and acks must be 'all'. If these values are not explicitly set by the user, suitable values will be chosen. If incompatible values are set, a ConfigException will be thrown.\""
TRANSACTION_TIMEOUT_CONFIG = "String  \"transaction.timeout.ms\""
TRANSACTION_TIMEOUT_DOC = "String  \"The maximum amount of time in ms that the transaction coordinator will wait for a transaction status update from the producer before proactively aborting the ongoing transaction.If this value is larger than the transaction.max.timeout.ms setting in the broker, the request will fail with a `InvalidTransactionTimeout` error.\""
TRANSACTIONAL_ID_CONFIG = "String  \"transactional.id\""
TRANSACTIONAL_ID_DOC = "String  \"The TransactionalId to use for transactional delivery. This enables reliability semantics which span multiple producer sessions since it allows the client to guarantee that transactions using the same TransactionalId have been completed prior to starting any new transactions. If no TransactionalId is provided, then the producer is limited to idempotent delivery. Note that enable.idempotence must be enabled if a TransactionalId is configured. The default is <code>null</code>, which means transactions cannot be used. Note that transactions requires a cluster of at least three brokers by default what is the recommended setting for production; for development you can change this, by adjusting broker setting `transaction.state.log.replication.factor`.\""
def ():
    '''returns ProducerConfig\n\n
    (final Properties props)\n
    (final Map<String, Object> props)\n
    '''
