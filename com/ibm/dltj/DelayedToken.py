token_type_close = "int  0"
token_type_std = "int  1"
token_type_unkown = "int  2"
token_type_breakpoint = "int  3"
token_type_punctuation = "int  4"
token_type_reset = "int  5"
token_type_startGroup = "int  6"
token_type_closeGroup = "int  7"
token_type_fork = "int  8"
token_type_addToFork = "int  9"
token_type_mergeRoutes = "int  10"
def DelayedToken():
'''public DelayedToken()
'''
pass
def tokenUnzip():
'''public String[] tokenUnzip(final String s)
'''
pass
def close():
'''public String close()
'''
pass
def createStd():
'''public String createStd(final int i, final int j, final int k, final GlossCollection e)
'''
pass
def createUnknown():
'''public String createUnknown(final int i, final int j, final int k, final int l)
'''
pass
def createBreakpoint():
'''public String createBreakpoint(final int i, final int j, final int k)
'''
pass
def createPunctuation():
'''public String createPunctuation(final int i, final int j, final int k, final int l)
'''
pass
def reset():
'''public String reset(final UniLexAnalyzer e)
'''
pass
def startGroup():
'''public String startGroup(final int i, final int j, final int k)
'''
pass
def closeGroup():
'''public String closeGroup(final int i)
'''
pass
def fork():
'''public String fork()
'''
pass
def addToFork():
'''public String addToFork()
'''
pass
def mergeRoutes():
'''public String mergeRoutes(final int i)
'''
pass
